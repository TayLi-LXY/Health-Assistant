"""
ç®€åŒ–çš„çŸ¥è¯†åº“æ„å»ºè„šæœ¬
ä½¿ç”¨åŸºæœ¬çš„å‘é‡åŒ–æ–¹æ³•ï¼Œé¿å…å¤æ‚çš„æ¨¡å‹ä¸‹è½½é—®é¢˜
"""

import json
import os
from pathlib import Path
from tqdm import tqdm

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# è®¾ç½®å›½å†…é•œåƒæº
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# æ¨¡å‹é€‰æ‹©
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
VECTOR_STORE_DIR = "knowledge_base/chroma_db_small"


def load_processed_chunks():
    """åŠ è½½é¢„å¤„ç†åçš„ chunks"""
    chunks_path = Path("data/processed_kb_chunks.json")
    if not chunks_path.exists():
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°é¢„å¤„ç†æ–‡ä»¶ {chunks_path}")
        return []
    
    print(f"åŠ è½½é¢„å¤„ç†æ–‡ä»¶ï¼š{chunks_path}")
    with open(chunks_path, "r", encoding="utf-8") as f:
        chunks = json.load(f)
    
    print(f"æˆåŠŸåŠ è½½ {len(chunks)} ä¸ª chunks")
    return chunks


def build_vector_store():
    """æ„å»ºå‘é‡åº“"""
    print("å¼€å§‹æ„å»ºå‘é‡åº“...")
    
    # 1. åŠ è½½æ•°æ®
    chunks = load_processed_chunks()
    if not chunks:
        print("é”™è¯¯ï¼šæ²¡æœ‰æ•°æ®å¯å¤„ç†")
        return None
    
    # 2. åˆ›å»ºå‘é‡å­˜å‚¨ç›®å½•
    os.makedirs(VECTOR_STORE_DIR, exist_ok=True)
    
    # 3. åˆå§‹åŒ– Embeddings
    print(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼š{EMBEDDING_MODEL}")
    print("æ³¨æ„ï¼šé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL,
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )
        print("åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼")
    except Exception as e:
        print(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹æ—¶å‡ºé”™ï¼š{e}")
        print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
        return None
    
    # 4. åˆå§‹åŒ– Chroma
    print(f"åˆå§‹åŒ– Chroma å‘é‡åº“ï¼š{VECTOR_STORE_DIR}")
    vector_store = Chroma(
        persist_directory=VECTOR_STORE_DIR,
        embedding_function=embeddings,
        collection_name="health_kb"
    )
    
    # 5. åˆ†æ‰¹å¤„ç†
    batch_size = 32
    total_chunks = len(chunks)
    print(f"å¼€å§‹æ‰¹é‡æ’å…¥å‘é‡åº“ï¼Œå…± {total_chunks} ä¸ª chunksï¼Œæ‰¹å¤§å°ï¼š{batch_size}")
    
    for i in tqdm(range(0, total_chunks, batch_size), desc="å‘é‡åŒ–è¿›åº¦"):
        batch = chunks[i : i + batch_size]
        
        batch_texts = [c["content"] for c in batch]
        batch_metadatas = []
        
        for c in batch:
            batch_metadatas.append({
                "source_url": c.get("source_url", ""),
                "title": c.get("title", ""),
                "chunk_id": c.get("chunk_id", ""),
                "chunk_index": c.get("chunk_index", 0),
                "document_type": c.get("document_type", "unknown")
            })
        
        try:
            vector_store.add_texts(texts=batch_texts, metadatas=batch_metadatas)
        except Exception as e:
            print(f"æ’å…¥æ‰¹æ¬¡ {i//batch_size + 1} æ—¶å‡ºé”™ï¼š{e}")
            continue
    
    # 6. æŒä¹…åŒ–
    vector_store.persist()
    print(f"âœ… å‘é‡åº“æ„å»ºå®Œæˆï¼")
    print(f"ğŸ“ å‘é‡åº“ä¿å­˜ä½ç½®ï¼š{VECTOR_STORE_DIR}")
    
    # 7. éªŒè¯
    count = vector_store._collection.count()
    print(f"ğŸ“Š å‘é‡åº“ä¸­åŒ…å« {count} ä¸ªæ–‡æ¡£")
    
    return vector_store


def main():
    print("=== å¥åº·çŸ¥è¯†åº“æ„å»ºè„šæœ¬ ===")
    print("ä½¿ç”¨å›½å†…é•œåƒæºä¸‹è½½æ¨¡å‹ï¼Œå¸¦è¿›åº¦æ¡æ˜¾ç¤º")
    print("=" * 50)
    
    vector_store = build_vector_store()
    
    if vector_store:
        print("\nğŸ‰ æ„å»ºæˆåŠŸï¼")
        print("\nå¦‚ä½•ä½¿ç”¨çŸ¥è¯†åº“ï¼š")
        print("1. å¯åŠ¨åç«¯æœåŠ¡ï¼špython -m uvicorn main:app --reload")
        print("2. è®¿é—®å‰ç«¯ï¼šhttp://localhost:5173")
        print("3. æµ‹è¯•æ£€ç´¢åŠŸèƒ½ï¼šåœ¨å‰ç«¯è¾“å…¥å¥åº·é—®é¢˜")
    else:
        print("\nâŒ æ„å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()
